## (EXL2)

A standalone Python/C++/CUDA implementation of Llama for use with 4-bit GPTQ weights, designed to be fast and memory-efficient on modern GPUs. This was developed by Turboderp under an MIT License and can be found [here](https://github.com/turboderp/exllama/tree/master)